import pandas as pd

# Load cleaned dataset
df = pd.read_excel("Final_Bacteria_New 320.xlsx")

# Target variable
y = df["Compressive Strength"]

# Input features (EXCLUDE target)
X = df.drop(columns=["Compressive Strength"])

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.30,      # 30% testing
    random_state=42,     # reproducibility
    shuffle=True
)

print("Training samples:", X_train.shape[0])
print("Testing samples:", X_test.shape[0])

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

# Fit ONLY on training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform testing data
X_test_scaled = scaler.transform(X_test)

from sklearn.model_selection import KFold

kf = KFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)

print("5-fold cross-validation is ready.")

##Cross-Validation with a Model (Random Forest)

##(I will repeat this for XGB, LGB, GBR, CatBoost)

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import numpy as np

rf = RandomForestRegressor(
    n_estimators=300,
    random_state=42
)

cv_r2 = cross_val_score(
    rf,
    X_train_scaled,
    y_train,
    cv=kf,
    scoring="r2"
)

print("5-fold CV R² scores:", cv_r2)
print("Mean CV R²:", np.mean(cv_r2))
print("Std CV R²:", np.std(cv_r2))

rf.fit(X_train_scaled, y_train)

#evaluate on the 30% Test Set
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

y_pred = rf.predict(X_test_scaled)

r2 = r2_score(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
mae = mean_absolute_error(y_test, y_pred)
mape = (abs((y_test - y_pred) / y_test).mean()) * 100

print(f"Test R²   : {r2:.3f}")
print(f"Test RMSE: {rmse:.3f}")
print(f"Test MAE : {mae:.3f}")
print(f"Test MAPE: {mape:.2f}%")

#

